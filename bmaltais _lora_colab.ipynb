{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1oO4oXtXAC6Q6AoAqboDlpXPMu0nfl9zs","timestamp":1687475942471}],"gpuType":"T4","authorship_tag":"ABX9TyP8beGJKDBJw+Bpb5OEuXib"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"c677324e2d494da38fb4c3faaf6191be":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"success","description":"✓ Done","disabled":true,"icon":"","layout":"IPY_MODEL_3c3dfed9069b4e44b94ec803e6809f6c","style":"IPY_MODEL_e8959f3bf03f4bfda7d24900be7a3375","tooltip":""}},"3c3dfed9069b4e44b94ec803e6809f6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":"50px","object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8959f3bf03f4bfda7d24900be7a3375":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"76ad738ed42345188355b36c796053a5":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"success","description":"✓ Done","disabled":true,"icon":"","layout":"IPY_MODEL_104a3431ba4b4178a302899c6af76b8f","style":"IPY_MODEL_5a0ecfea07d544fc982946591bf872dc","tooltip":""}},"104a3431ba4b4178a302899c6af76b8f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":"50px","object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a0ecfea07d544fc982946591bf872dc":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"cellView":"form","id":"NJHhOrOrYKhX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687476045821,"user_tz":-180,"elapsed":18171,"user":{"displayName":"Эдуард Одинцов","userId":"11632212540674405888"}},"outputId":"71e28b70-37b3-45a7-9a95-3a715f3937ff"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["#@markdown #Step 1️⃣: Mounting Google Drive\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","source":["#@markdown #Step 2️⃣: Kohya SS WebUI Installation\n","\n","#@markdown Note: If Google Drive is not connected, the code will use Colab storage instead.\n","\n","#@title\n","# Import necessary libraries\n","from IPython.display import clear_output\n","from IPython.utils import capture\n","from subprocess import getoutput\n","import ipywidgets as widgets\n","import sys\n","import fileinput\n","import os\n","import time\n","import shutil\n","\n","# Remove OLD WebUI Installation\n","shutil.rmtree('/content/gdrive/MyDrive/sd', ignore_errors=True)\n","\n","# WebUI Installation\n","%env TF_CPP_MIN_LOG_LEVEL=1\n","\n","!apt -y update -qq\n","!wget http://launchpadlibrarian.net/367274644/libgoogle-perftools-dev_2.5-2.2ubuntu3_amd64.deb\n","!wget https://launchpad.net/ubuntu/+source/google-perftools/2.5-2.2ubuntu3/+build/14795286/+files/google-perftools_2.5-2.2ubuntu3_all.deb\n","!wget https://launchpad.net/ubuntu/+source/google-perftools/2.5-2.2ubuntu3/+build/14795286/+files/libtcmalloc-minimal4_2.5-2.2ubuntu3_amd64.deb\n","!wget https://launchpad.net/ubuntu/+source/google-perftools/2.5-2.2ubuntu3/+build/14795286/+files/libgoogle-perftools4_2.5-2.2ubuntu3_amd64.deb\n","!apt install -qq libunwind8-dev\n","!dpkg -i *.deb\n","%env LD_PRELOAD=libtcmalloc.so\n","!rm *.deb\n","\n","# Check if Google Drive is connected\n","if not os.path.exists(\"/content/gdrive/MyDrive/\"):\n","    print(\"Gdrive not connected, using colab storage ...\")\n","    time.sleep(4)\n","    !mkdir -p /content/gdrive/MyDrive/\n","\n","# Clone the repository and create necessary directories\n","with capture.capture_output() as cap:\n","    def inf(msg, style, wdth):\n","        inf = widgets.Button(description=msg, disabled=True, button_style=style, layout=widgets.Layout(min_width=wdth))\n","        display(inf)\n","\n","    %mkdir -p /content/gdrive/MyDrive/sd\n","    %cd /content/gdrive/MyDrive/sd\n","    !git clone https://github.com/boginskiii/kohya_ss kohya_ss_colab\n","    !mkdir -p /content/gdrive/MyDrive/sd/kohya_ss_colab/cache/huggingface\n","    !ln -s /content/gdrive/MyDrive/sd/kohya_ss_colab/cache/huggingface /root/.cache/\n","\n","# Reset the git repository and pull the latest changes\n","with capture.capture_output() as cap:\n","    %cd /content/gdrive/MyDrive/sd/kohya_ss_colab/\n","    !git reset --hard\n","    time.sleep(1)\n","\n","print(\"Updating the repository...\")\n","!git pull\n","\n","# Clear the output and display the success message\n","clear_output()\n","inf(\"✓ Done\", \"success\", \"50px\")"],"metadata":{"cellView":"form","id":"Wr3_bNcuYQSh","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["c677324e2d494da38fb4c3faaf6191be","3c3dfed9069b4e44b94ec803e6809f6c","e8959f3bf03f4bfda7d24900be7a3375"]},"executionInfo":{"status":"ok","timestamp":1687476078479,"user_tz":-180,"elapsed":28513,"user":{"displayName":"Эдуард Одинцов","userId":"11632212540674405888"}},"outputId":"e740a3d0-fea3-478f-ca49-36eb1b899926"},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":["Button(button_style='success', description='✓ Done', disabled=True, layout=Layout(min_width='50px'), style=But…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c677324e2d494da38fb4c3faaf6191be"}},"metadata":{}}]},{"cell_type":"code","source":["#@markdown #Step 3️⃣: Requirements Installation\n","\n","#@markdown Now that we have downloaded the Kohya SS WebUI, we need to install the necessary requirements.\n","\n","# Print the status message\n","print(\"Installing requirements...\")\n","\n","# Change the working directory to the project folder\n","%cd /content/gdrive/MyDrive/sd/kohya_ss_colab/\n","\n","# Install the requirements\n","with capture.capture_output() as cap:\n","    # Uncomment the following line if you need to install specific versions of torch and torchvision\n","    !pip install torch==2.0.0+cu118 torchvision==0.15.1+cu118 --extra-index-url https://download.pytorch.org/whl/cu118\n","    !pip install xformers==0.0.19\n","\n","    # Install the requirements from the requirements.txt file\n","    !pip install -r requirements.txt\n","\n","\n","# Clear the output to keep the notebook clean\n","clear_output()\n","\n","# Print the success message\n","inf(\"✓ Done\", \"success\", \"50px\")"],"metadata":{"cellView":"form","id":"BmWfN6imZA_k","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["76ad738ed42345188355b36c796053a5","104a3431ba4b4178a302899c6af76b8f","5a0ecfea07d544fc982946591bf872dc"]},"executionInfo":{"status":"ok","timestamp":1687476466761,"user_tz":-180,"elapsed":335546,"user":{"displayName":"Эдуард Одинцов","userId":"11632212540674405888"}},"outputId":"d9774bc4-b63d-41de-8196-4c554ce9b524"},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":["Button(button_style='success', description='✓ Done', disabled=True, layout=Layout(min_width='50px'), style=But…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76ad738ed42345188355b36c796053a5"}},"metadata":{}}]},{"cell_type":"code","source":["#@markdown #Optional🛠️: Download File or PreTrained Model\n","PreTrained_Model = \"https://civitai.com/api/download/models/9593?type=Model&format=SafeTensor&size=full&fp=fp16\"  # @param {'type': 'string'}\n","!wget --content-disposition $PreTrained_Model"],"metadata":{"cellView":"form","id":"G8Un2xTEZOpK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687476615435,"user_tz":-180,"elapsed":144536,"user":{"displayName":"Эдуард Одинцов","userId":"11632212540674405888"}},"outputId":"77937693-521e-428f-df44-ec4d7f38979e"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-06-22 23:27:48--  https://civitai.com/api/download/models/9593?type=Model\n","Resolving civitai.com (civitai.com)... 104.18.22.206, 104.18.23.206, 2606:4700::6812:17ce, ...\n","Connecting to civitai.com (civitai.com)|104.18.22.206|:443... connected.\n","HTTP request sent, awaiting response... 307 Temporary Redirect\n","Location: https://civitai-delivery-worker-prod-2023-06-01.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com/48396/model/aToZovyaRPGArtistTools.9AJU.safetensors?X-Amz-Expires=86400&response-content-disposition=attachment%3B%20filename%3D%22aZovyaRPGArtistTools_sd21768V1.safetensors%22&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=2fea663d76bd24a496545da373d610fc/20230622/us-east-1/s3/aws4_request&X-Amz-Date=20230622T232750Z&X-Amz-SignedHeaders=host&X-Amz-Signature=03e946a6912550840b1f4c4faa0784d137a967b41473153a22d7c11b9047f293 [following]\n","--2023-06-22 23:27:50--  https://civitai-delivery-worker-prod-2023-06-01.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com/48396/model/aToZovyaRPGArtistTools.9AJU.safetensors?X-Amz-Expires=86400&response-content-disposition=attachment%3B%20filename%3D%22aZovyaRPGArtistTools_sd21768V1.safetensors%22&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=2fea663d76bd24a496545da373d610fc/20230622/us-east-1/s3/aws4_request&X-Amz-Date=20230622T232750Z&X-Amz-SignedHeaders=host&X-Amz-Signature=03e946a6912550840b1f4c4faa0784d137a967b41473153a22d7c11b9047f293\n","Resolving civitai-delivery-worker-prod-2023-06-01.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com (civitai-delivery-worker-prod-2023-06-01.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com)... 104.18.8.90, 104.18.9.90, 2606:4700::6812:85a, ...\n","Connecting to civitai-delivery-worker-prod-2023-06-01.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com (civitai-delivery-worker-prod-2023-06-01.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com)|104.18.8.90|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 5159974609 (4.8G) [application/octet-stream]\n","Saving to: ‘aZovyaRPGArtistTools_sd21768V1.safetensors’\n","\n","aZovyaRPGArtistTool  58%[==========>         ]   2.82G  36.4MB/s    in 79s     \n","\n","2023-06-22 23:29:10 (36.5 MB/s) - Connection closed at byte 3028811776. Retrying.\n","\n","--2023-06-22 23:29:11--  (try: 2)  https://civitai-delivery-worker-prod-2023-06-01.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com/48396/model/aToZovyaRPGArtistTools.9AJU.safetensors?X-Amz-Expires=86400&response-content-disposition=attachment%3B%20filename%3D%22aZovyaRPGArtistTools_sd21768V1.safetensors%22&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=2fea663d76bd24a496545da373d610fc/20230622/us-east-1/s3/aws4_request&X-Amz-Date=20230622T232750Z&X-Amz-SignedHeaders=host&X-Amz-Signature=03e946a6912550840b1f4c4faa0784d137a967b41473153a22d7c11b9047f293\n","Connecting to civitai-delivery-worker-prod-2023-06-01.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com (civitai-delivery-worker-prod-2023-06-01.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com)|104.18.8.90|:443... connected.\n","HTTP request sent, awaiting response... 206 Partial Content\n","Length: 5159974609 (4.8G), 2131162833 (2.0G) remaining [application/octet-stream]\n","Saving to: ‘aZovyaRPGArtistTools_sd21768V1.safetensors’\n","\n","aZovyaRPGArtistTool 100%[+++++++++++========>]   4.80G  25.4MB/s    in 61s     \n","\n","2023-06-22 23:30:13 (33.4 MB/s) - ‘aZovyaRPGArtistTools_sd21768V1.safetensors’ saved [5159974609/5159974609]\n","\n"]}]},{"cell_type":"code","source":["#@markdown #Step 4️⃣: Start Kohya ss WebUI\n","\n","User = \"\" #@param {type:\"string\"}\n","Password = \"\" #@param {type:\"string\"}\n","\n","\n","if User and Password:\n","    # Run the Kohya GUI with the provided credentials\n","    !python /content/gdrive/MyDrive/sd/kohya_ss_colab/kohya_gui.py --username $User --password $Password --share --headless\n","else:\n","    # Run the Kohya GUI without credentials\n","    !python /content/gdrive/MyDrive/sd/kohya_ss_colab/kohya_gui.py --share --headless"],"metadata":{"cellView":"form","id":"3dKo-KICZYs9","colab":{"base_uri":"https://localhost:8080/"},"outputId":"de68254b-f4ef-4292-e4cf-f77a866d84de"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-06-22 23:43:06.383429: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-06-22 23:43:07.626014: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-06-22 23:43:07.626143: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-06-22 23:43:07.626168: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","prepare tokenizer\n","Downloading (…)tokenizer/vocab.json: 1.06MB [00:00, 4.45MB/s]\n","Downloading (…)tokenizer/merges.txt: 525kB [00:00, 1.17MB/s]\n","Downloading (…)cial_tokens_map.json: 100% 460/460 [00:00<00:00, 413kB/s]\n","Downloading (…)okenizer_config.json: 100% 824/824 [00:00<00:00, 697kB/s]\n","Using DreamBooth method.\n","prepare images.\n","found directory /content/gdrive/MyDrive/IMG/40_stripizdunchik contains 17 image files\n","No caption file found for 17 images. Training will continue without captions for these images. If class token exists, it will be used. / 17枚の画像にキャプションファイルが見つかりませんでした。これらの画像についてはキャプションなしで学習を続行します。class tokenが存在する場合はそれを使います。\n","/content/gdrive/MyDrive/IMG/40_stripizdunchik/stripizdunchik (1).png\n","/content/gdrive/MyDrive/IMG/40_stripizdunchik/stripizdunchik (10).png\n","/content/gdrive/MyDrive/IMG/40_stripizdunchik/stripizdunchik (11).png\n","/content/gdrive/MyDrive/IMG/40_stripizdunchik/stripizdunchik (12).png\n","/content/gdrive/MyDrive/IMG/40_stripizdunchik/stripizdunchik (13).png\n","/content/gdrive/MyDrive/IMG/40_stripizdunchik/stripizdunchik (14).png... and 12 more\n","680 train images with repeating.\n","0 reg images.\n","no regularization images / 正則化画像が見つかりませんでした\n","[Dataset 0]\n","  batch_size: 2\n","  resolution: (768, 768)\n","  enable_bucket: True\n","  min_bucket_reso: 256\n","  max_bucket_reso: 1024\n","  bucket_reso_steps: 64\n","  bucket_no_upscale: True\n","\n","  [Subset 0 of Dataset 0]\n","    image_dir: \"/content/gdrive/MyDrive/IMG/40_stripizdunchik\"\n","    image_count: 17\n","    num_repeats: 40\n","    shuffle_caption: False\n","    keep_tokens: 0\n","    caption_dropout_rate: 0.0\n","    caption_dropout_every_n_epoches: 0\n","    caption_tag_dropout_rate: 0.0\n","    color_aug: False\n","    flip_aug: False\n","    face_crop_aug_range: None\n","    random_crop: False\n","    token_warmup_min: 1,\n","    token_warmup_step: 0,\n","    is_reg: False\n","    class_tokens: stripizdunchik\n","    caption_extension: .txt\n","\n","\n","[Dataset 0]\n","loading image sizes.\n","100% 17/17 [00:14<00:00,  1.16it/s]\n","make buckets\n","min_bucket_reso and max_bucket_reso are ignored if bucket_no_upscale is set, because bucket reso is defined by image size automatically / bucket_no_upscaleが指定された場合は、bucketの解像度は画像サイズから自動計算されるため、min_bucket_resoとmax_bucket_resoは無視されます\n","number of images (including repeats) / 各bucketの画像枚数（繰り返し回数を含む）\n","bucket 0: resolution (768, 768), count: 680\n","mean ar error (without repeats): 0.0\n","preparing accelerator\n","Using accelerator 0.15.0 or above.\n","loading model for process 0/1\n","load StableDiffusion checkpoint: /content/gdrive/MyDrive/sd/kohya_ss_colab/aZovyaRPGArtistTools_sd21768V1.safetensors\n","loading u-net: <All keys matched successfully>\n","loading vae: <All keys matched successfully>\n","loading text encoder: <All keys matched successfully>\n","CrossAttention.forward has been replaced to enable xformers.\n","import network module: lycoris.kohya\n","[Dataset 0]\n","caching latents.\n","100% 17/17 [00:15<00:00,  1.06it/s]\n","Using rank adaptation algo: loha\n","Apply different lora dim for conv layer\n","Conv Dim: 8, Linear Dim: 32\n","Apply different alpha value for conv layer\n","Conv alpha: 4.0, Linear alpha: 16.0\n","Use Dropout value: 0.0\n","Create LyCORIS Module\n","create LyCORIS for Text Encoder: 138 modules.\n","Create LyCORIS Module\n","create LyCORIS for U-Net: 278 modules.\n","enable LyCORIS for text encoder\n","enable LyCORIS for U-Net\n","preparing optimizer, data loader etc.\n","Deprecated: use prepare_optimizer_params(text_encoder_lr, unet_lr, learning_rate) instead of prepare_optimizer_params(text_encoder_lr, unet_lr)\n","use AdamW optimizer | {}\n","running training / 学習開始\n","  num train images * repeats / 学習画像の数×繰り返し回数: 680\n","  num reg images / 正則化画像の数: 0\n","  num batches per epoch / 1epochのバッチ数: 340\n","  num epochs / epoch数: 12\n","  batch size per device / バッチサイズ: 2\n","  gradient accumulation steps / 勾配を合計するステップ数 = 8\n","  total optimization steps / 学習ステップ数: 510\n","steps:   0% 0/510 [00:00<?, ?it/s]\n","epoch 1/12\n","steps:   2% 8/510 [01:50<1:55:14, 13.77s/it, loss=0.185]"]}]}]}